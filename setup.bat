@echo off
REM Dear Me - Automated Setup Script (Windows)

echo ðŸŒŸ Dear Me - Automated Setup
echo =============================

REM Check prerequisites
echo ðŸ” Checking prerequisites...

python --version >nul 2>&1
if %errorlevel% neq 0 (
    echo âŒ Python not found. Please install from https://www.python.org/
    pause
    exit /b 1
)

node -v >nul 2>&1
if %errorlevel% neq 0 (
    echo âŒ Node.js not found. Please install from https://nodejs.org/
    pause
    exit /b 1
)

ollama --version >nul 2>&1
if %errorlevel% neq 0 (
    echo âŒ Ollama not found. Please install from https://ollama.ai/
    pause
    exit /b 1
)

echo âœ… All prerequisites found

REM Setup Ollama
echo.
echo ðŸ¤– Setting up AI models...
ollama list | findstr "llama3.1:8b" >nul 2>&1
if %errorlevel% neq 0 (
    echo ðŸ“¥ Downloading Llama 3.1 model (this may take a few minutes)...
    ollama pull llama3.1:8b
) else (
    echo âœ… Llama 3.1 model already downloaded
)

echo ðŸš€ Starting Ollama server...
start "Ollama Server" ollama serve
timeout /t 3 >nul

REM Setup Backend
echo.
echo ðŸ”§ Setting up backend...
cd backend

if not exist "venv" (
    echo ðŸ“¦ Creating virtual environment...
    python -m venv venv
)

echo ðŸ“¦ Installing backend dependencies...
call venv\Scripts\activate.bat
pip install -r requirements.txt

echo ðŸš€ Starting backend server...
start "Backend Server" cmd /c "venv\Scripts\activate.bat && python main.py"
cd ..
timeout /t 3 >nul

REM Setup Frontend
echo.
echo ðŸŽ¨ Setting up frontend...
cd frontend

if not exist "node_modules" (
    echo ðŸ“¦ Installing frontend dependencies...
    npm install
)

echo ðŸš€ Starting frontend server...
start "Frontend Server" npm start
cd ..

timeout /t 5 >nul

echo.
echo ðŸŽ‰ Setup complete!
echo ðŸ“± Your app should open automatically at: http://localhost:3000
echo ðŸ“š API docs available at: http://localhost:8001/docs
echo.
echo ðŸ’¡ Close the terminal windows to stop all services
echo.
pause